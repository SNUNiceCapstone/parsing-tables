{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "from typing import List, Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "class FinancialStatementParser:\n",
    "    def __init__(self, html_content: str):\n",
    "        self.soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        self.body_elements = [el for el in self.soup.body.children if isinstance(el, Tag)]\n",
    "        self.parsed_tables: List[pd.DataFrame] = []\n",
    "        self.annotation_table_map: Dict[str, List[pd.DataFrame]] = {}\n",
    "        self.parsed_json: Dict[str, Any] = {}\n",
    "        self.found_cashflow = False\n",
    "        self.skip_next = False\n",
    "        self.last_main_note = None\n",
    "        self.subsection_chain: List[str] = []\n",
    "\n",
    "    def _expand_table_header(self, header_rows):\n",
    "        max_cols = max(sum(int(cell.get(\"colspan\", 1)) for cell in row.find_all(['th', 'td']))\n",
    "                       for row in header_rows)\n",
    "        grid = [[\"\" for _ in range(max_cols)] for _ in range(len(header_rows))]\n",
    "\n",
    "        for row_idx, row in enumerate(header_rows):\n",
    "            col_idx = 0\n",
    "            for cell in row.find_all(['th', 'td']):\n",
    "                while col_idx < max_cols and grid[row_idx][col_idx] != \"\":\n",
    "                    col_idx += 1\n",
    "                rowspan = int(cell.get(\"rowspan\", 1))\n",
    "                colspan = int(cell.get(\"colspan\", 1))\n",
    "                text = cell.get_text(strip=True).replace('\\xa0', '')\n",
    "                for i in range(rowspan):\n",
    "                    for j in range(colspan):\n",
    "                        if row_idx + i < len(grid) and col_idx + j < max_cols:\n",
    "                            grid[row_idx + i][col_idx + j] = text\n",
    "                col_idx += colspan\n",
    "\n",
    "        return [\"|\".join([grid[r][c] for r in range(len(grid)) if grid[r][c]])\n",
    "                for c in range(max_cols)]\n",
    "\n",
    "    def _expand_body_row(self, row, col_len):\n",
    "        cells = []\n",
    "        for cell in row.find_all(['td', 'th']):\n",
    "            colspan = int(cell.get(\"colspan\", 1))\n",
    "            text = cell.get_text(strip=True).replace('\\xa0', '')\n",
    "            cells.extend([text] + [''] * (colspan - 1))\n",
    "        return cells + [\"\"] * (col_len - len(cells))\n",
    "\n",
    "    def parse_tables(self):\n",
    "        current_note = None\n",
    "        self.subsection_chain = []\n",
    "\n",
    "        for el in self.body_elements:\n",
    "            if el.name == 'table':\n",
    "                if self.skip_next:\n",
    "                    self.skip_next = False\n",
    "                    continue\n",
    "                if '자 본 변 동 표' in el.get_text():\n",
    "                    self.skip_next = True\n",
    "                    continue\n",
    "                if '현 금 흐 름 표' in el.get_text():\n",
    "                    self.found_cashflow = True\n",
    "\n",
    "                header_rows, body_rows = [], []\n",
    "                thead, tbody = el.find(\"thead\"), el.find(\"tbody\")\n",
    "                if thead and tbody:\n",
    "                    header_rows = thead.find_all(\"tr\")\n",
    "                    body_rows = tbody.find_all(\"tr\")\n",
    "                else:\n",
    "                    rows = el.find_all(\"tr\")\n",
    "                    header_rows, body_rows = rows[:2], rows[2:]\n",
    "\n",
    "                try:\n",
    "                    headers = self._expand_table_header(header_rows)\n",
    "                    data = [self._expand_body_row(row, len(headers)) for row in body_rows]\n",
    "                    df = pd.DataFrame(data, columns=headers)\n",
    "                    df = df.replace('', np.nan).dropna(how='all')\n",
    "\n",
    "                    if self.found_cashflow and self.last_main_note:\n",
    "                        note_label = self.last_main_note\n",
    "                        if self.subsection_chain:\n",
    "                            note_label += '_' + '_'.join(self.subsection_chain)\n",
    "                        if note_label not in self.annotation_table_map:\n",
    "                            self.annotation_table_map[note_label] = []\n",
    "                        self.annotation_table_map[note_label].append(df)\n",
    "                    else:\n",
    "                        self.parsed_tables.append(df)\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ 표 처리 오류: {e}\")\n",
    "\n",
    "            elif el.name in ['p', 'span', 'div']:\n",
    "                text = el.get_text(strip=True).replace('\\xa0', '')\n",
    "                if self.found_cashflow:\n",
    "                    if '계속' in text and self.last_main_note:\n",
    "                        continue  # 유지\n",
    "\n",
    "                    main_match = re.match(r'^(\\d+(\\.\\d+)*)([:\\-_\\.]\\s*)(.*)', text)\n",
    "                    if main_match:\n",
    "                        num = main_match.group(1)\n",
    "                        title = main_match.group(4).split(':')[0].strip()\n",
    "                        self.last_main_note = f\"{num}. {title}\"\n",
    "                        self.subsection_chain = []\n",
    "                        continue\n",
    "\n",
    "                    sub_match = re.match(r'^([\\u3131-\\u314e]\\.|\\(\\d+\\))\\s*(.*)', text)\n",
    "                    if sub_match:\n",
    "                        self.subsection_chain.append(sub_match.group(1).strip())\n",
    "\n",
    "    def save_tables(self, output_excel: str):\n",
    "        with pd.ExcelWriter(output_excel) as writer:\n",
    "            for i, df in enumerate(self.parsed_tables):\n",
    "                df.to_excel(writer, sheet_name=f'Table_{i+1}', index=False)\n",
    "            for note, dfs in self.annotation_table_map.items():\n",
    "                for idx, df in enumerate(dfs):\n",
    "                    safe_note = note.replace('/', '_').replace(':', '_').replace('\\\\', '_')\n",
    "                    sheet_name = safe_note[:25] + f\"_{idx+1}\" if len(dfs) > 1 else safe_note[:31]\n",
    "                    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    def parse_to_json(self) -> Dict[str, Any]:\n",
    "        result = {\n",
    "            'metadata': {\n",
    "                'parsed_at': datetime.now().isoformat(),\n",
    "                'total_tables': len(self.parsed_tables)\n",
    "            },\n",
    "            'tables': []\n",
    "        }\n",
    "        for i, df in enumerate(self.parsed_tables):\n",
    "            headers = df.columns.tolist()\n",
    "            data = df.fillna(\"\").values.tolist()\n",
    "            result['tables'].append({\n",
    "                'table_index': i,\n",
    "                'structure': {'headers': headers, 'data': data}\n",
    "            })\n",
    "        for note, dfs in self.annotation_table_map.items():\n",
    "            for idx, df in enumerate(dfs):\n",
    "                label = f\"{note}_{idx+1}\" if len(dfs) > 1 else note\n",
    "                headers = df.columns.tolist()\n",
    "                data = df.fillna(\"\").values.tolist()\n",
    "                result['tables'].append({\n",
    "                    'note': label,\n",
    "                    'structure': {'headers': headers, 'data': data}\n",
    "                })\n",
    "        self.parsed_json = result\n",
    "        return result\n",
    "\n",
    "    def save_json(self, output_json: str, pretty: bool = True):\n",
    "        if not self.parsed_json:\n",
    "            self.parse_to_json()\n",
    "        with open(output_json, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.parsed_json, f, ensure_ascii=False, indent=2 if pretty else None)\n",
    "\n",
    "\n",
    "def parse_financial_statement(input_html_path: str, output_excel: str, output_json: str):\n",
    "    with open(input_html_path, 'r', encoding='cp949') as f:\n",
    "        html = f.read()\n",
    "    parser = FinancialStatementParser(html)\n",
    "    parser.parse_tables()\n",
    "    parser.save_tables(output_excel)\n",
    "    parser.parse_to_json()\n",
    "    parser.save_json(output_json)\n",
    "    print(f\"✅ 저장 완료: {output_excel}, {output_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: 삼성전자_2014.xlsx, 삼성전자_2014.json\n"
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "parse_financial_statement(\n",
    "    'samsung/감사보고서_4496517.htm',\n",
    "    '삼성전자_2014.xlsx',\n",
    "    '삼성전자_2014.json'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
